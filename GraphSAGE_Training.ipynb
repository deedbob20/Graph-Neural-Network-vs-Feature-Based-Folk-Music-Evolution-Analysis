{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to construct and train a GraphSAGE model on a corpus of British Folk/Traditional melodies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to train GraphSAGE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.datasets import PPI\n",
    "from torch_geometric.loader import DataLoader, LinkNeighborLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Using the same train, val, test splits as the identical dataset for GNN comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'split_data/10_class_50yrN_split.pkl' # Change as needed\n",
    "with open(data_path, 'rb') as f:\n",
    "    # Load the serialized object from the file\n",
    "    tune_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    '''GraphSAGE Model'''\n",
    "\n",
    "    # Define layers:\n",
    "    def __init__(self, dim_in, dim_h, num_classes):\n",
    "        super().__init__()\n",
    "        self.sage1 = SAGEConv(dim_in, dim_h)\n",
    "        self.sage2 = SAGEConv(dim_h, dim_h // 2)\n",
    "        self.linear = torch.nn.Linear(dim_h // 2, num_classes)\n",
    "\n",
    "    # Define forward function:\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.sage1(x, edge_index)\n",
    "        h = torch.relu(h)\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.sage2(h, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.linear(h)\n",
    "\n",
    "        return h # return single numeric value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimiser, criterion, n_epochs, saved_model_path, print_metrics=True, save_best_model=False):\n",
    "    ''' \n",
    "    Function to train a GraphSAGE model.\n",
    "\n",
    "    Inputs:\n",
    "    - model (torch.nn.Module): GraphSAGE model\n",
    "    - train_loader (pytorch_geometric.loader.NeighborLoader)\n",
    "    - optmiser (torch.optim)\n",
    "    - criterion (torch.nn): Loss function\n",
    "    - n_epochs (int): Number of epochs to train for\n",
    "\n",
    "    Returns:\n",
    "    - average_train_loss (float): Training loss averaged over batches\n",
    "    - average_val_loss (float): Validation loss averaged over batches\n",
    "    - peak_cal_acc (float): Peak validation accuracy reached during training\n",
    "    \n",
    "    '''\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Training loop:\n",
    "\n",
    "    peak_val_acc = 0.0\n",
    "    train_loss_lst = []\n",
    "    val_loss_lst = []\n",
    "    epoch_lst = []\n",
    "    for epoch in range(n_epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_accuracy = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        val_loss = 0\n",
    "        num_batches = len(train_loader)\n",
    "\n",
    "        # Train in mini-batches:\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # Feed data through model:\n",
    "            out = model(batch.x, batch.edge_index)\n",
    "\n",
    "            # Calc. loss:\n",
    "            loss = criterion(out[batch.train_mask], batch.y[batch.train_mask])\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Calculate train accuracy\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct = pred[batch.train_mask] == batch.y[batch.train_mask]\n",
    "            train_correct += correct.sum().item()\n",
    "            train_total += batch.train_mask.sum().item()\n",
    "        \n",
    "        average_train_loss = train_loss / num_batches\n",
    "        train_accuracy = train_correct / train_total\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "\n",
    "            # Val loss:\n",
    "            model.eval()\n",
    "            val_accuracy = 0.0\n",
    "            num_val_nodes = 0\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for batch in val_loader:\n",
    "                    batch = batch.to(device)\n",
    "                    out = model(batch.x, batch.edge_index)\n",
    "                    loss = criterion(out[batch.val_mask], batch.y[batch.val_mask])\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    # Calculate validation accuracy\n",
    "                    pred = out.argmax(dim=1)\n",
    "                    correct = pred[batch.val_mask] == batch.y[batch.val_mask]\n",
    "                    num_val_nodes += batch.val_mask.sum().item()\n",
    "                    val_accuracy += correct.sum().item()\n",
    "\n",
    "            average_val_loss = val_loss / num_batches\n",
    "            val_accuracy /= num_val_nodes\n",
    "\n",
    "            # Add train and val loss to lst\n",
    "            train_loss_lst.append(train_accuracy)\n",
    "            val_loss_lst.append(val_accuracy)\n",
    "            epoch_lst.append(epoch)\n",
    "\n",
    "            if val_accuracy > peak_val_acc:\n",
    "                peak_val_acc = val_accuracy\n",
    "\n",
    "                # Save best model:\n",
    "                if save_best_model:\n",
    "                    torch.save(model.state_dict(), saved_model_path)\n",
    "                    print(\"Model saved\")\n",
    "\n",
    "            if print_metrics:    \n",
    "                print('Epoch: ', epoch)\n",
    "                print('Train loss: ', average_train_loss)\n",
    "                print('Train accuracy: ', train_accuracy)\n",
    "                print('Val loss: ', average_val_loss)\n",
    "                print('Val accuracy: ', val_accuracy)\n",
    "\n",
    "    # Plot losses:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epoch_lst, train_loss_lst, label='Training Accuracy')\n",
    "    plt.plot(epoch_lst, val_loss_lst, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training and Validation Accuracy of GraphSAGE Model')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return average_train_loss, average_val_loss, peak_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data, data_loader, print_metrics=True):\n",
    "    ''' \n",
    "    Function to train a GraphSAGE model.\n",
    "\n",
    "    Inputs:\n",
    "    - model (torch.nn.Module): GraphSAGE model\n",
    "    - data_loader (pytorch_geometric.loader.NeighborLoader)\n",
    "    - print_metrics (bool): Whether to print testing results (Default = True)\n",
    "\n",
    "    Returns:\n",
    "    - test_accuracy (float): Test accuracy\n",
    "    \n",
    "    '''\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Test init:\n",
    "    model.eval()\n",
    "\n",
    "    test_accuracy = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    num_batches = len(data_loader)\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Test in mini-batches:\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            # Feed data through model:\n",
    "            out = model(batch.x, batch.edge_index)\n",
    "\n",
    "            # Calculate test accuracy\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct = pred[batch.test_mask] == batch.y[batch.test_mask]\n",
    "            test_correct += correct.sum().item()\n",
    "            test_total += batch.test_mask.sum().item()\n",
    "\n",
    "            # Append for confusion matrix\n",
    "            all_preds.append(pred[batch.test_mask].cpu().numpy())\n",
    "            all_labels.append(batch.y[batch.test_mask].cpu().numpy())\n",
    "\n",
    "    \n",
    "    test_accuracy = test_correct / test_total\n",
    "\n",
    "    if print_metrics:    \n",
    "        print('Test accuracy: ', test_accuracy)\n",
    "\n",
    "        # Convert prediction and label tensors to numpy arrays\n",
    "        preds = np.concatenate(all_preds)\n",
    "        labels = np.concatenate(all_labels)\n",
    "\n",
    "        # Build confusion matrix:\n",
    "        if num_classes == 4:\n",
    "            classes = ('1700', '1750', '1800', '1850')\n",
    "        if num_classes == 5:\n",
    "            classes = ('1650', '1700', '1750', '1800', '1850') \n",
    "        if num_classes == 10:\n",
    "            classes = ('1650', '1675', '1700', '1725', '1750', '1775', '1800',  '1825', '1850', '1875')\n",
    "        cf_matrix = confusion_matrix(labels, preds) # build confusion matrix\n",
    "        cf_matrix_df = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                        columns = [i for i in classes]) # normalise, convert to cols, store in dataframe \n",
    "        plt.figure(figsize = (12,7))\n",
    "        plt.title('Folk-Song Dating Confusion Matrix')\n",
    "        sn.heatmap(cf_matrix_df, annot=True)\n",
    "\n",
    "\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_neighbours_1: 5, num_neighbours_2: 5, dim_h: 16, lr: 0.001, achieved peak val_acc: 0.2733333333333333\n",
      "num_neighbours_1: 5, num_neighbours_2: 5, dim_h: 16, lr: 0.01, achieved peak val_acc: 0.10135135135135136\n",
      "num_neighbours_1: 5, num_neighbours_2: 5, dim_h: 32, lr: 0.001, achieved peak val_acc: 0.2080536912751678\n",
      "num_neighbours_1: 5, num_neighbours_2: 5, dim_h: 32, lr: 0.01, achieved peak val_acc: 0.1\n",
      "num_neighbours_1: 5, num_neighbours_2: 5, dim_h: 64, lr: 0.001, achieved peak val_acc: 0.22297297297297297\n",
      "num_neighbours_1: 5, num_neighbours_2: 5, dim_h: 64, lr: 0.01, achieved peak val_acc: 0.24\n",
      "num_neighbours_1: 5, num_neighbours_2: 5, dim_h: 128, lr: 0.001, achieved peak val_acc: 0.26\n",
      "num_neighbours_1: 5, num_neighbours_2: 5, dim_h: 128, lr: 0.01, achieved peak val_acc: 0.26174496644295303\n",
      "num_neighbours_1: 5, num_neighbours_2: 15, dim_h: 16, lr: 0.001, achieved peak val_acc: 0.21333333333333335\n",
      "num_neighbours_1: 5, num_neighbours_2: 15, dim_h: 16, lr: 0.01, achieved peak val_acc: 0.11409395973154363\n",
      "num_neighbours_1: 5, num_neighbours_2: 15, dim_h: 32, lr: 0.001, achieved peak val_acc: 0.14093959731543623\n",
      "num_neighbours_1: 5, num_neighbours_2: 15, dim_h: 32, lr: 0.01, achieved peak val_acc: 0.13333333333333333\n",
      "num_neighbours_1: 5, num_neighbours_2: 15, dim_h: 64, lr: 0.001, achieved peak val_acc: 0.26\n",
      "num_neighbours_1: 5, num_neighbours_2: 15, dim_h: 64, lr: 0.01, achieved peak val_acc: 0.12666666666666668\n",
      "num_neighbours_1: 5, num_neighbours_2: 15, dim_h: 128, lr: 0.001, achieved peak val_acc: 0.24666666666666667\n",
      "num_neighbours_1: 5, num_neighbours_2: 15, dim_h: 128, lr: 0.01, achieved peak val_acc: 0.29333333333333333\n",
      "num_neighbours_1: 5, num_neighbours_2: 30, dim_h: 16, lr: 0.001, achieved peak val_acc: 0.19333333333333333\n",
      "num_neighbours_1: 5, num_neighbours_2: 30, dim_h: 16, lr: 0.01, achieved peak val_acc: 0.11333333333333333\n",
      "num_neighbours_1: 5, num_neighbours_2: 30, dim_h: 32, lr: 0.001, achieved peak val_acc: 0.22\n",
      "num_neighbours_1: 5, num_neighbours_2: 30, dim_h: 32, lr: 0.01, achieved peak val_acc: 0.2866666666666667\n",
      "num_neighbours_1: 5, num_neighbours_2: 30, dim_h: 64, lr: 0.001, achieved peak val_acc: 0.24\n",
      "num_neighbours_1: 5, num_neighbours_2: 30, dim_h: 64, lr: 0.01, achieved peak val_acc: 0.12\n",
      "num_neighbours_1: 5, num_neighbours_2: 30, dim_h: 128, lr: 0.001, achieved peak val_acc: 0.24666666666666667\n",
      "num_neighbours_1: 5, num_neighbours_2: 30, dim_h: 128, lr: 0.01, achieved peak val_acc: 0.2733333333333333\n",
      "num_neighbours_1: 15, num_neighbours_2: 5, dim_h: 16, lr: 0.001, achieved peak val_acc: 0.15333333333333332\n",
      "num_neighbours_1: 15, num_neighbours_2: 5, dim_h: 16, lr: 0.01, achieved peak val_acc: 0.2733333333333333\n",
      "num_neighbours_1: 15, num_neighbours_2: 5, dim_h: 32, lr: 0.001, achieved peak val_acc: 0.26666666666666666\n",
      "num_neighbours_1: 15, num_neighbours_2: 5, dim_h: 32, lr: 0.01, achieved peak val_acc: 0.09333333333333334\n",
      "num_neighbours_1: 15, num_neighbours_2: 5, dim_h: 64, lr: 0.001, achieved peak val_acc: 0.23333333333333334\n",
      "num_neighbours_1: 15, num_neighbours_2: 5, dim_h: 64, lr: 0.01, achieved peak val_acc: 0.2866666666666667\n",
      "num_neighbours_1: 15, num_neighbours_2: 5, dim_h: 128, lr: 0.001, achieved peak val_acc: 0.26666666666666666\n",
      "num_neighbours_1: 15, num_neighbours_2: 5, dim_h: 128, lr: 0.01, achieved peak val_acc: 0.2733333333333333\n",
      "num_neighbours_1: 15, num_neighbours_2: 15, dim_h: 16, lr: 0.001, achieved peak val_acc: 0.12\n",
      "num_neighbours_1: 15, num_neighbours_2: 15, dim_h: 16, lr: 0.01, achieved peak val_acc: 0.10666666666666667\n",
      "num_neighbours_1: 15, num_neighbours_2: 15, dim_h: 32, lr: 0.001, achieved peak val_acc: 0.21333333333333335\n",
      "num_neighbours_1: 15, num_neighbours_2: 15, dim_h: 32, lr: 0.01, achieved peak val_acc: 0.2866666666666667\n",
      "num_neighbours_1: 15, num_neighbours_2: 15, dim_h: 64, lr: 0.001, achieved peak val_acc: 0.21333333333333335\n",
      "num_neighbours_1: 15, num_neighbours_2: 15, dim_h: 64, lr: 0.01, achieved peak val_acc: 0.2733333333333333\n",
      "num_neighbours_1: 15, num_neighbours_2: 15, dim_h: 128, lr: 0.001, achieved peak val_acc: 0.2866666666666667\n",
      "num_neighbours_1: 15, num_neighbours_2: 15, dim_h: 128, lr: 0.01, achieved peak val_acc: 0.28\n",
      "num_neighbours_1: 15, num_neighbours_2: 30, dim_h: 16, lr: 0.001, achieved peak val_acc: 0.14666666666666667\n",
      "num_neighbours_1: 15, num_neighbours_2: 30, dim_h: 16, lr: 0.01, achieved peak val_acc: 0.12666666666666668\n",
      "num_neighbours_1: 15, num_neighbours_2: 30, dim_h: 32, lr: 0.001, achieved peak val_acc: 0.25333333333333335\n",
      "num_neighbours_1: 15, num_neighbours_2: 30, dim_h: 32, lr: 0.01, achieved peak val_acc: 0.15333333333333332\n",
      "num_neighbours_1: 15, num_neighbours_2: 30, dim_h: 64, lr: 0.001, achieved peak val_acc: 0.22666666666666666\n",
      "num_neighbours_1: 15, num_neighbours_2: 30, dim_h: 64, lr: 0.01, achieved peak val_acc: 0.1\n",
      "num_neighbours_1: 15, num_neighbours_2: 30, dim_h: 128, lr: 0.001, achieved peak val_acc: 0.26666666666666666\n",
      "num_neighbours_1: 15, num_neighbours_2: 30, dim_h: 128, lr: 0.01, achieved peak val_acc: 0.3\n",
      "num_neighbours_1: 30, num_neighbours_2: 5, dim_h: 16, lr: 0.001, achieved peak val_acc: 0.26666666666666666\n",
      "num_neighbours_1: 30, num_neighbours_2: 5, dim_h: 16, lr: 0.01, achieved peak val_acc: 0.26\n",
      "num_neighbours_1: 30, num_neighbours_2: 5, dim_h: 32, lr: 0.001, achieved peak val_acc: 0.16\n",
      "num_neighbours_1: 30, num_neighbours_2: 5, dim_h: 32, lr: 0.01, achieved peak val_acc: 0.09333333333333334\n",
      "num_neighbours_1: 30, num_neighbours_2: 5, dim_h: 64, lr: 0.001, achieved peak val_acc: 0.28\n",
      "num_neighbours_1: 30, num_neighbours_2: 5, dim_h: 64, lr: 0.01, achieved peak val_acc: 0.29333333333333333\n",
      "num_neighbours_1: 30, num_neighbours_2: 5, dim_h: 128, lr: 0.001, achieved peak val_acc: 0.25333333333333335\n",
      "num_neighbours_1: 30, num_neighbours_2: 5, dim_h: 128, lr: 0.01, achieved peak val_acc: 0.25333333333333335\n",
      "num_neighbours_1: 30, num_neighbours_2: 15, dim_h: 16, lr: 0.001, achieved peak val_acc: 0.22666666666666666\n",
      "num_neighbours_1: 30, num_neighbours_2: 15, dim_h: 16, lr: 0.01, achieved peak val_acc: 0.19333333333333333\n",
      "num_neighbours_1: 30, num_neighbours_2: 15, dim_h: 32, lr: 0.001, achieved peak val_acc: 0.25333333333333335\n",
      "num_neighbours_1: 30, num_neighbours_2: 15, dim_h: 32, lr: 0.01, achieved peak val_acc: 0.09333333333333334\n",
      "num_neighbours_1: 30, num_neighbours_2: 15, dim_h: 64, lr: 0.001, achieved peak val_acc: 0.19333333333333333\n",
      "num_neighbours_1: 30, num_neighbours_2: 15, dim_h: 64, lr: 0.01, achieved peak val_acc: 0.2866666666666667\n",
      "num_neighbours_1: 30, num_neighbours_2: 15, dim_h: 128, lr: 0.001, achieved peak val_acc: 0.3\n",
      "num_neighbours_1: 30, num_neighbours_2: 15, dim_h: 128, lr: 0.01, achieved peak val_acc: 0.30666666666666664\n",
      "num_neighbours_1: 30, num_neighbours_2: 30, dim_h: 16, lr: 0.001, achieved peak val_acc: 0.11333333333333333\n",
      "num_neighbours_1: 30, num_neighbours_2: 30, dim_h: 16, lr: 0.01, achieved peak val_acc: 0.2733333333333333\n",
      "num_neighbours_1: 30, num_neighbours_2: 30, dim_h: 32, lr: 0.001, achieved peak val_acc: 0.20666666666666667\n",
      "num_neighbours_1: 30, num_neighbours_2: 30, dim_h: 32, lr: 0.01, achieved peak val_acc: 0.09333333333333334\n",
      "num_neighbours_1: 30, num_neighbours_2: 30, dim_h: 64, lr: 0.001, achieved peak val_acc: 0.2866666666666667\n",
      "num_neighbours_1: 30, num_neighbours_2: 30, dim_h: 64, lr: 0.01, achieved peak val_acc: 0.2866666666666667\n",
      "num_neighbours_1: 30, num_neighbours_2: 30, dim_h: 128, lr: 0.001, achieved peak val_acc: 0.32\n",
      "num_neighbours_1: 30, num_neighbours_2: 30, dim_h: 128, lr: 0.01, achieved peak val_acc: 0.32\n",
      "[((30, 30, 128, 0.001), 0.32), ((30, 30, 128, 0.01), 0.32), ((30, 15, 128, 0.01), 0.30666666666666664)]\n"
     ]
    }
   ],
   "source": [
    "### Perform grid-search to find optimum number of out_channels:\n",
    "\n",
    "dim_h_grid = [16, 32, 64, 128]\n",
    "num_neighbours_1 = [15, 30]\n",
    "num_neighbours_2 = [15, 30]\n",
    "lr_grid = [0.001, 0.01]\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for num_neighbours in num_neighbours_1:\n",
    "\n",
    "    for num_neighbours_second in num_neighbours_2:\n",
    "\n",
    "        # Params:\n",
    "        train_loader = NeighborLoader(\n",
    "        tune_data,\n",
    "        num_neighbors=[num_neighbours, num_neighbours_second], \n",
    "        batch_size = 800,\n",
    "        input_nodes=tune_data.train_mask,\n",
    "        )\n",
    "\n",
    "        # Params:\n",
    "        val_loader = NeighborLoader(\n",
    "        tune_data,\n",
    "        num_neighbors=[num_neighbours, num_neighbours_second], \n",
    "        batch_size = 800,\n",
    "        input_nodes=tune_data.val_mask,\n",
    "        )\n",
    "\n",
    "        for num_dims in dim_h_grid:\n",
    "            for lr in lr_grid:\n",
    "                peak_val_acc = 0.0\n",
    "                \n",
    "                dim_h = num_dims\n",
    "                dim_in = tune_data.num_features\n",
    "                epochs = 500\n",
    "\n",
    "                \n",
    "                # Train:\n",
    "                saved_model_path = 'None'\n",
    "                num_classes = 5\n",
    "                model = GraphSAGE(dim_in, dim_h, num_classes)\n",
    "\n",
    "                optimiser = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "                _, _, peak_val_acc = train_model(model, train_loader, val_loader, optimiser, criterion, epochs, saved_model_path, False)\n",
    "\n",
    "                results_dict[(num_neighbours, num_neighbours_second, num_dims, lr)] = peak_val_acc \n",
    "\n",
    "                print('num_neighbours_1: {num_neighbours}, num_neighbours_2: {num_neighbours_second}, dim_h: {dim_h}, lr: {lr}, achieved peak val_acc: {peak_val_acc}'.format(num_neighbours=num_neighbours, num_neighbours_second=num_neighbours_second, dim_h=dim_h, lr=lr, peak_val_acc=peak_val_acc))\n",
    "  \n",
    "# Print best:\n",
    "accuracy_lst = []\n",
    "for params, accuracy in results_dict.items():\n",
    "    accuracy_lst.append((params, accuracy))\n",
    "    \n",
    "accuracy_lst.sort(reverse=True, key=lambda x: x[1])\n",
    "top_3 = accuracy_lst[:3]\n",
    "\n",
    "print(top_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "dim_in = tune_data.num_features\n",
    "dim_h = 128\n",
    "num_classes = 10\n",
    "saved_model_path = 'run5_SAGE_best_model_10Classes_50yrN'\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "        tune_data,\n",
    "        num_neighbors=[15, 15], # n neighbours of a node and n neighbours for each of these neighbours\n",
    "        batch_size = 800,\n",
    "        input_nodes=tune_data.train_mask)\n",
    "\n",
    "val_loader = NeighborLoader(\n",
    "        tune_data,\n",
    "        num_neighbors=[15, 15], # n neighbours of a node and n neighbours for each of these neighbours\n",
    "        batch_size = 800,\n",
    "        input_nodes=tune_data.val_mask)\n",
    "\n",
    "test_loader = NeighborLoader(\n",
    "        tune_data,\n",
    "        num_neighbors=[15, 15], # n neighbours of a node and n neighbours for each of these neighbours\n",
    "        batch_size = 800,\n",
    "        input_nodes=tune_data.test_mask)\n",
    "\n",
    "# model\n",
    "model = GraphSAGE(dim_in, dim_h, num_classes)\n",
    "\n",
    "# Optimiser and loss criterion:\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n",
      "Epoch:  0\n",
      "Train loss:  8.422938346862793\n",
      "Train accuracy:  0.10714285714285714\n",
      "Val loss:  3.1857831478118896\n",
      "Val accuracy:  0.21333333333333335\n",
      "Epoch:  5\n",
      "Train loss:  4.159163951873779\n",
      "Train accuracy:  0.11714285714285715\n",
      "Val loss:  2.4459190368652344\n",
      "Val accuracy:  0.08\n",
      "Epoch:  10\n",
      "Train loss:  2.776630401611328\n",
      "Train accuracy:  0.13428571428571429\n",
      "Val loss:  2.263192653656006\n",
      "Val accuracy:  0.12666666666666668\n",
      "Epoch:  15\n",
      "Train loss:  2.422349214553833\n",
      "Train accuracy:  0.11714285714285715\n",
      "Val loss:  2.288421154022217\n",
      "Val accuracy:  0.1\n",
      "Epoch:  20\n",
      "Train loss:  2.339447498321533\n",
      "Train accuracy:  0.09428571428571429\n",
      "Val loss:  2.298563003540039\n",
      "Val accuracy:  0.11333333333333333\n",
      "Epoch:  25\n",
      "Train loss:  2.304237127304077\n",
      "Train accuracy:  0.11428571428571428\n",
      "Val loss:  2.300551652908325\n",
      "Val accuracy:  0.11333333333333333\n",
      "Epoch:  30\n",
      "Train loss:  2.3089160919189453\n",
      "Train accuracy:  0.10285714285714286\n",
      "Val loss:  2.300790309906006\n",
      "Val accuracy:  0.11333333333333333\n",
      "Epoch:  35\n",
      "Train loss:  2.302565336227417\n",
      "Train accuracy:  0.11571428571428571\n",
      "Val loss:  2.3015525341033936\n",
      "Val accuracy:  0.11333333333333333\n",
      "Epoch:  40\n",
      "Train loss:  2.311363935470581\n",
      "Train accuracy:  0.11285714285714285\n",
      "Val loss:  2.3015458583831787\n",
      "Val accuracy:  0.11333333333333333\n",
      "Epoch:  45\n",
      "Train loss:  2.290811538696289\n",
      "Train accuracy:  0.11285714285714285\n",
      "Val loss:  2.301786422729492\n",
      "Val accuracy:  0.11333333333333333\n",
      "Epoch:  50\n",
      "Train loss:  2.2888851165771484\n",
      "Train accuracy:  0.10571428571428572\n",
      "Val loss:  2.3011727333068848\n",
      "Val accuracy:  0.11333333333333333\n",
      "Epoch:  55\n",
      "Train loss:  2.283330202102661\n",
      "Train accuracy:  0.11714285714285715\n",
      "Val loss:  2.3005025386810303\n",
      "Val accuracy:  0.12666666666666668\n",
      "Epoch:  60\n",
      "Train loss:  2.2883036136627197\n",
      "Train accuracy:  0.11714285714285715\n",
      "Val loss:  2.2962002754211426\n",
      "Val accuracy:  0.12666666666666668\n",
      "Epoch:  65\n",
      "Train loss:  2.2710819244384766\n",
      "Train accuracy:  0.14142857142857143\n",
      "Val loss:  2.2831456661224365\n",
      "Val accuracy:  0.12\n",
      "Epoch:  70\n",
      "Train loss:  2.2793123722076416\n",
      "Train accuracy:  0.12285714285714286\n",
      "Val loss:  2.2728631496429443\n",
      "Val accuracy:  0.14\n",
      "Epoch:  75\n",
      "Train loss:  2.250464677810669\n",
      "Train accuracy:  0.12857142857142856\n",
      "Val loss:  2.257737159729004\n",
      "Val accuracy:  0.16666666666666666\n",
      "Epoch:  80\n",
      "Train loss:  2.251182794570923\n",
      "Train accuracy:  0.13285714285714287\n",
      "Val loss:  2.2274773120880127\n",
      "Val accuracy:  0.18\n",
      "Epoch:  85\n",
      "Train loss:  2.2252933979034424\n",
      "Train accuracy:  0.15714285714285714\n",
      "Val loss:  2.160125732421875\n",
      "Val accuracy:  0.21333333333333335\n",
      "Epoch:  90\n",
      "Train loss:  2.222318410873413\n",
      "Train accuracy:  0.14714285714285713\n",
      "Val loss:  2.1129186153411865\n",
      "Val accuracy:  0.20666666666666667\n",
      "Model saved\n",
      "Epoch:  95\n",
      "Train loss:  2.187382698059082\n",
      "Train accuracy:  0.15\n",
      "Val loss:  2.0985071659088135\n",
      "Val accuracy:  0.22\n",
      "Epoch:  100\n",
      "Train loss:  2.16947865486145\n",
      "Train accuracy:  0.13714285714285715\n",
      "Val loss:  2.0513412952423096\n",
      "Val accuracy:  0.20666666666666667\n",
      "Epoch:  105\n",
      "Train loss:  2.1428608894348145\n",
      "Train accuracy:  0.15\n",
      "Val loss:  2.0248963832855225\n",
      "Val accuracy:  0.19333333333333333\n",
      "Model saved\n",
      "Epoch:  110\n",
      "Train loss:  2.142599582672119\n",
      "Train accuracy:  0.13\n",
      "Val loss:  2.007958173751831\n",
      "Val accuracy:  0.22666666666666666\n",
      "Model saved\n",
      "Epoch:  115\n",
      "Train loss:  2.099108934402466\n",
      "Train accuracy:  0.16285714285714287\n",
      "Val loss:  1.987514853477478\n",
      "Val accuracy:  0.23333333333333334\n",
      "Epoch:  120\n",
      "Train loss:  2.1191556453704834\n",
      "Train accuracy:  0.16857142857142857\n",
      "Val loss:  1.9745235443115234\n",
      "Val accuracy:  0.21333333333333335\n",
      "Epoch:  125\n",
      "Train loss:  2.099740505218506\n",
      "Train accuracy:  0.16142857142857142\n",
      "Val loss:  1.968284249305725\n",
      "Val accuracy:  0.18666666666666668\n",
      "Epoch:  130\n",
      "Train loss:  2.075456142425537\n",
      "Train accuracy:  0.16285714285714287\n",
      "Val loss:  1.9601078033447266\n",
      "Val accuracy:  0.18666666666666668\n",
      "Epoch:  135\n",
      "Train loss:  2.0374395847320557\n",
      "Train accuracy:  0.18428571428571427\n",
      "Val loss:  1.9451463222503662\n",
      "Val accuracy:  0.2\n",
      "Epoch:  140\n",
      "Train loss:  2.0564887523651123\n",
      "Train accuracy:  0.1742857142857143\n",
      "Val loss:  1.9452643394470215\n",
      "Val accuracy:  0.20666666666666667\n",
      "Epoch:  145\n",
      "Train loss:  2.064192533493042\n",
      "Train accuracy:  0.2042857142857143\n",
      "Val loss:  1.9413857460021973\n",
      "Val accuracy:  0.21333333333333335\n",
      "Model saved\n",
      "Epoch:  150\n",
      "Train loss:  2.0472986698150635\n",
      "Train accuracy:  0.17285714285714285\n",
      "Val loss:  1.9196020364761353\n",
      "Val accuracy:  0.24\n",
      "Epoch:  155\n",
      "Train loss:  2.0254292488098145\n",
      "Train accuracy:  0.21285714285714286\n",
      "Val loss:  1.9262367486953735\n",
      "Val accuracy:  0.18666666666666668\n",
      "Epoch:  160\n",
      "Train loss:  2.009312152862549\n",
      "Train accuracy:  0.2057142857142857\n",
      "Val loss:  1.930402398109436\n",
      "Val accuracy:  0.18666666666666668\n",
      "Epoch:  165\n",
      "Train loss:  2.005600690841675\n",
      "Train accuracy:  0.20285714285714285\n",
      "Val loss:  1.8982714414596558\n",
      "Val accuracy:  0.22\n",
      "Epoch:  170\n",
      "Train loss:  2.002002716064453\n",
      "Train accuracy:  0.21714285714285714\n",
      "Val loss:  1.9065779447555542\n",
      "Val accuracy:  0.22666666666666666\n",
      "Epoch:  175\n",
      "Train loss:  2.0130183696746826\n",
      "Train accuracy:  0.2057142857142857\n",
      "Val loss:  1.9093778133392334\n",
      "Val accuracy:  0.18666666666666668\n",
      "Epoch:  180\n",
      "Train loss:  1.9861865043640137\n",
      "Train accuracy:  0.21285714285714286\n",
      "Val loss:  1.9091060161590576\n",
      "Val accuracy:  0.19333333333333333\n",
      "Epoch:  185\n",
      "Train loss:  1.974780797958374\n",
      "Train accuracy:  0.21142857142857144\n",
      "Val loss:  1.9048410654067993\n",
      "Val accuracy:  0.18\n",
      "Epoch:  190\n",
      "Train loss:  1.977677822113037\n",
      "Train accuracy:  0.23857142857142857\n",
      "Val loss:  1.895372748374939\n",
      "Val accuracy:  0.24\n",
      "Epoch:  195\n",
      "Train loss:  1.9769655466079712\n",
      "Train accuracy:  0.2257142857142857\n",
      "Val loss:  1.8715993165969849\n",
      "Val accuracy:  0.24\n",
      "Epoch:  200\n",
      "Train loss:  2.01747727394104\n",
      "Train accuracy:  0.22714285714285715\n",
      "Val loss:  1.8786975145339966\n",
      "Val accuracy:  0.21333333333333335\n",
      "Epoch:  205\n",
      "Train loss:  1.9900715351104736\n",
      "Train accuracy:  0.22285714285714286\n",
      "Val loss:  1.8999512195587158\n",
      "Val accuracy:  0.22666666666666666\n",
      "Epoch:  210\n",
      "Train loss:  1.9614611864089966\n",
      "Train accuracy:  0.2257142857142857\n",
      "Val loss:  1.8782365322113037\n",
      "Val accuracy:  0.19333333333333333\n",
      "Epoch:  215\n",
      "Train loss:  1.9689702987670898\n",
      "Train accuracy:  0.21285714285714286\n",
      "Val loss:  1.872420072555542\n",
      "Val accuracy:  0.24\n",
      "Epoch:  220\n",
      "Train loss:  1.9648984670639038\n",
      "Train accuracy:  0.22142857142857142\n",
      "Val loss:  1.8884902000427246\n",
      "Val accuracy:  0.20666666666666667\n",
      "Epoch:  225\n",
      "Train loss:  1.9290105104446411\n",
      "Train accuracy:  0.2357142857142857\n",
      "Val loss:  1.8952726125717163\n",
      "Val accuracy:  0.2\n",
      "Epoch:  230\n",
      "Train loss:  1.9457974433898926\n",
      "Train accuracy:  0.21428571428571427\n",
      "Val loss:  1.8754726648330688\n",
      "Val accuracy:  0.2\n",
      "Epoch:  235\n",
      "Train loss:  1.9352519512176514\n",
      "Train accuracy:  0.21571428571428572\n",
      "Val loss:  1.8697772026062012\n",
      "Val accuracy:  0.22\n",
      "Model saved\n",
      "Epoch:  240\n",
      "Train loss:  1.950230360031128\n",
      "Train accuracy:  0.21142857142857144\n",
      "Val loss:  1.8607563972473145\n",
      "Val accuracy:  0.25333333333333335\n",
      "Epoch:  245\n",
      "Train loss:  1.9267939329147339\n",
      "Train accuracy:  0.24142857142857144\n",
      "Val loss:  1.8749585151672363\n",
      "Val accuracy:  0.24666666666666667\n",
      "Epoch:  250\n",
      "Train loss:  1.923785924911499\n",
      "Train accuracy:  0.2\n",
      "Val loss:  1.8736742734909058\n",
      "Val accuracy:  0.22666666666666666\n",
      "Epoch:  255\n",
      "Train loss:  1.9468486309051514\n",
      "Train accuracy:  0.21714285714285714\n",
      "Val loss:  1.8738573789596558\n",
      "Val accuracy:  0.21333333333333335\n",
      "Epoch:  260\n",
      "Train loss:  1.914124608039856\n",
      "Train accuracy:  0.24571428571428572\n",
      "Val loss:  1.855601191520691\n",
      "Val accuracy:  0.22666666666666666\n",
      "Model saved\n",
      "Epoch:  265\n",
      "Train loss:  1.921994924545288\n",
      "Train accuracy:  0.2557142857142857\n",
      "Val loss:  1.861487865447998\n",
      "Val accuracy:  0.26\n",
      "Epoch:  270\n",
      "Train loss:  1.9137344360351562\n",
      "Train accuracy:  0.2257142857142857\n",
      "Val loss:  1.8510563373565674\n",
      "Val accuracy:  0.25333333333333335\n",
      "Epoch:  275\n",
      "Train loss:  1.9251072406768799\n",
      "Train accuracy:  0.2357142857142857\n",
      "Val loss:  1.8656654357910156\n",
      "Val accuracy:  0.22666666666666666\n",
      "Epoch:  280\n",
      "Train loss:  1.9269325733184814\n",
      "Train accuracy:  0.23285714285714285\n",
      "Val loss:  1.8554229736328125\n",
      "Val accuracy:  0.22\n",
      "Epoch:  285\n",
      "Train loss:  1.9028737545013428\n",
      "Train accuracy:  0.24857142857142858\n",
      "Val loss:  1.856597900390625\n",
      "Val accuracy:  0.19333333333333333\n",
      "Epoch:  290\n",
      "Train loss:  1.8978888988494873\n",
      "Train accuracy:  0.26142857142857145\n",
      "Val loss:  1.8608804941177368\n",
      "Val accuracy:  0.23333333333333334\n",
      "Epoch:  295\n",
      "Train loss:  1.9069010019302368\n",
      "Train accuracy:  0.24285714285714285\n",
      "Val loss:  1.8262766599655151\n",
      "Val accuracy:  0.24666666666666667\n",
      "Epoch:  300\n",
      "Train loss:  1.8926410675048828\n",
      "Train accuracy:  0.24285714285714285\n",
      "Val loss:  1.8480379581451416\n",
      "Val accuracy:  0.23333333333333334\n",
      "Epoch:  305\n",
      "Train loss:  1.908737063407898\n",
      "Train accuracy:  0.2342857142857143\n",
      "Val loss:  1.8490790128707886\n",
      "Val accuracy:  0.24\n",
      "Epoch:  310\n",
      "Train loss:  1.9005252122879028\n",
      "Train accuracy:  0.25285714285714284\n",
      "Val loss:  1.8159395456314087\n",
      "Val accuracy:  0.22666666666666666\n",
      "Epoch:  315\n",
      "Train loss:  1.9202312231063843\n",
      "Train accuracy:  0.24285714285714285\n",
      "Val loss:  1.829624891281128\n",
      "Val accuracy:  0.22666666666666666\n",
      "Epoch:  320\n",
      "Train loss:  1.8781625032424927\n",
      "Train accuracy:  0.2542857142857143\n",
      "Val loss:  1.8557177782058716\n",
      "Val accuracy:  0.21333333333333335\n",
      "Epoch:  325\n",
      "Train loss:  1.9097532033920288\n",
      "Train accuracy:  0.2257142857142857\n",
      "Val loss:  1.8361315727233887\n",
      "Val accuracy:  0.23333333333333334\n",
      "Epoch:  330\n",
      "Train loss:  1.8950477838516235\n",
      "Train accuracy:  0.24714285714285714\n",
      "Val loss:  1.829734444618225\n",
      "Val accuracy:  0.24\n",
      "Epoch:  335\n",
      "Train loss:  1.8849384784698486\n",
      "Train accuracy:  0.2542857142857143\n",
      "Val loss:  1.8101983070373535\n",
      "Val accuracy:  0.22666666666666666\n",
      "Epoch:  340\n",
      "Train loss:  1.8706809282302856\n",
      "Train accuracy:  0.24857142857142858\n",
      "Val loss:  1.8339040279388428\n",
      "Val accuracy:  0.22666666666666666\n",
      "Epoch:  345\n",
      "Train loss:  1.891860008239746\n",
      "Train accuracy:  0.24428571428571427\n",
      "Val loss:  1.7900059223175049\n",
      "Val accuracy:  0.21333333333333335\n",
      "Epoch:  350\n",
      "Train loss:  1.8554006814956665\n",
      "Train accuracy:  0.27\n",
      "Val loss:  1.8262394666671753\n",
      "Val accuracy:  0.24666666666666667\n",
      "Epoch:  355\n",
      "Train loss:  1.833793044090271\n",
      "Train accuracy:  0.26142857142857145\n",
      "Val loss:  1.799985408782959\n",
      "Val accuracy:  0.24\n",
      "Epoch:  360\n",
      "Train loss:  1.8648829460144043\n",
      "Train accuracy:  0.2571428571428571\n",
      "Val loss:  1.8223284482955933\n",
      "Val accuracy:  0.24\n",
      "Epoch:  365\n",
      "Train loss:  1.8712522983551025\n",
      "Train accuracy:  0.26\n",
      "Val loss:  1.810490369796753\n",
      "Val accuracy:  0.23333333333333334\n",
      "Epoch:  370\n",
      "Train loss:  1.871960997581482\n",
      "Train accuracy:  0.24857142857142858\n",
      "Val loss:  1.8262423276901245\n",
      "Val accuracy:  0.22666666666666666\n",
      "Epoch:  375\n",
      "Train loss:  1.8431655168533325\n",
      "Train accuracy:  0.26142857142857145\n",
      "Val loss:  1.7917324304580688\n",
      "Val accuracy:  0.21333333333333335\n",
      "Model saved\n",
      "Epoch:  380\n",
      "Train loss:  1.8422287702560425\n",
      "Train accuracy:  0.2714285714285714\n",
      "Val loss:  1.799317479133606\n",
      "Val accuracy:  0.3\n",
      "Epoch:  385\n",
      "Train loss:  1.8631826639175415\n",
      "Train accuracy:  0.26857142857142857\n",
      "Val loss:  1.7955138683319092\n",
      "Val accuracy:  0.22666666666666666\n",
      "Epoch:  390\n",
      "Train loss:  1.8350003957748413\n",
      "Train accuracy:  0.27285714285714285\n",
      "Val loss:  1.8134934902191162\n",
      "Val accuracy:  0.24\n",
      "Epoch:  395\n",
      "Train loss:  1.859026551246643\n",
      "Train accuracy:  0.2671428571428571\n",
      "Val loss:  1.7861366271972656\n",
      "Val accuracy:  0.20666666666666667\n",
      "Epoch:  400\n",
      "Train loss:  1.8419573307037354\n",
      "Train accuracy:  0.2671428571428571\n",
      "Val loss:  1.816046953201294\n",
      "Val accuracy:  0.21333333333333335\n",
      "Epoch:  405\n",
      "Train loss:  1.8255196809768677\n",
      "Train accuracy:  0.28\n",
      "Val loss:  1.803442120552063\n",
      "Val accuracy:  0.25333333333333335\n",
      "Epoch:  410\n",
      "Train loss:  1.8304111957550049\n",
      "Train accuracy:  0.2742857142857143\n",
      "Val loss:  1.8084690570831299\n",
      "Val accuracy:  0.26\n",
      "Epoch:  415\n",
      "Train loss:  1.8254016637802124\n",
      "Train accuracy:  0.25285714285714284\n",
      "Val loss:  1.797787070274353\n",
      "Val accuracy:  0.22\n",
      "Epoch:  420\n",
      "Train loss:  1.7897535562515259\n",
      "Train accuracy:  0.2985714285714286\n",
      "Val loss:  1.7949554920196533\n",
      "Val accuracy:  0.23333333333333334\n",
      "Epoch:  425\n",
      "Train loss:  1.8024790287017822\n",
      "Train accuracy:  0.26857142857142857\n",
      "Val loss:  1.7892438173294067\n",
      "Val accuracy:  0.22\n",
      "Epoch:  430\n",
      "Train loss:  1.8036974668502808\n",
      "Train accuracy:  0.28714285714285714\n",
      "Val loss:  1.7893176078796387\n",
      "Val accuracy:  0.24\n",
      "Epoch:  435\n",
      "Train loss:  1.8231269121170044\n",
      "Train accuracy:  0.26857142857142857\n",
      "Val loss:  1.798248291015625\n",
      "Val accuracy:  0.24\n",
      "Epoch:  440\n",
      "Train loss:  1.8195455074310303\n",
      "Train accuracy:  0.27285714285714285\n",
      "Val loss:  1.7827666997909546\n",
      "Val accuracy:  0.26666666666666666\n",
      "Epoch:  445\n",
      "Train loss:  1.8046305179595947\n",
      "Train accuracy:  0.2714285714285714\n",
      "Val loss:  1.785187005996704\n",
      "Val accuracy:  0.24666666666666667\n",
      "Epoch:  450\n",
      "Train loss:  1.8139653205871582\n",
      "Train accuracy:  0.29714285714285715\n",
      "Val loss:  1.791162133216858\n",
      "Val accuracy:  0.24\n",
      "Epoch:  455\n",
      "Train loss:  1.8188450336456299\n",
      "Train accuracy:  0.2671428571428571\n",
      "Val loss:  1.8316949605941772\n",
      "Val accuracy:  0.23333333333333334\n",
      "Epoch:  460\n",
      "Train loss:  1.8165044784545898\n",
      "Train accuracy:  0.27714285714285714\n",
      "Val loss:  1.7940844297409058\n",
      "Val accuracy:  0.2733333333333333\n",
      "Epoch:  465\n",
      "Train loss:  1.805773377418518\n",
      "Train accuracy:  0.28\n",
      "Val loss:  1.7667334079742432\n",
      "Val accuracy:  0.2866666666666667\n",
      "Epoch:  470\n",
      "Train loss:  1.766384243965149\n",
      "Train accuracy:  0.2985714285714286\n",
      "Val loss:  1.7706180810928345\n",
      "Val accuracy:  0.24\n",
      "Epoch:  475\n",
      "Train loss:  1.785579800605774\n",
      "Train accuracy:  0.3171428571428571\n",
      "Val loss:  1.7925254106521606\n",
      "Val accuracy:  0.2866666666666667\n",
      "Epoch:  480\n",
      "Train loss:  1.7980728149414062\n",
      "Train accuracy:  0.2914285714285714\n",
      "Val loss:  1.7878930568695068\n",
      "Val accuracy:  0.26666666666666666\n",
      "Epoch:  485\n",
      "Train loss:  1.7768663167953491\n",
      "Train accuracy:  0.2857142857142857\n",
      "Val loss:  1.8112976551055908\n",
      "Val accuracy:  0.22\n",
      "Epoch:  490\n",
      "Train loss:  1.8137809038162231\n",
      "Train accuracy:  0.29\n",
      "Val loss:  1.8209224939346313\n",
      "Val accuracy:  0.26\n",
      "Epoch:  495\n",
      "Train loss:  1.7767823934555054\n",
      "Train accuracy:  0.27285714285714285\n",
      "Val loss:  1.7943212985992432\n",
      "Val accuracy:  0.26\n",
      "Epoch:  500\n",
      "Train loss:  1.7873501777648926\n",
      "Train accuracy:  0.29285714285714287\n",
      "Val loss:  1.8159183263778687\n",
      "Val accuracy:  0.22666666666666666\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss, peak_val_acc = train_model(model, train_loader, val_loader, optimiser, criterion, 500, saved_model_path, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = saved_model_path\n",
    "\n",
    "dim_in = tune_data.num_features\n",
    "dim_h = 128\n",
    "num_classes = 10\n",
    "model = GraphSAGE(dim_in, dim_h, num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracies = []\n",
    "for i in range(5):\n",
    "    test_accuracy = test_model(model, tune_data, test_loader, num_classes)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "avg_accuracy = np.mean(test_accuracies)\n",
    "print(avg_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
